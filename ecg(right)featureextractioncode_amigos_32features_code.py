# -*- coding: utf-8 -*-
"""ECG(Right)FeatureExtractionCode_AMigos_32Features_code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AhaWXcByiX1Rlsywp43uBU9FoGuE2CmD

# Drive Mounting and Dependencies
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install wfdb
!pip install opensignalsreader
!pip install pyhrv
!pip install biosppy
!pip install pyhrv
!pip install hrv-analysis

import os
import sys
import csv

#median
import statistics
from statistics import median

import os
from glob import glob

# data science
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import Ellipse
import seaborn as sns

# signal processing
from scipy import signal
from scipy.ndimage import label
from scipy.stats import zscore
from scipy.interpolate import interp1d
from scipy.integrate import trapz

# physionet data
import wfdb
from wfdb import processing

import numpy as np
import pandas as pd
pd.set_option('display.max_colwidth',100000)

from hrvanalysis import remove_outliers, remove_ectopic_beats, interpolate_nan_values
from hrvanalysis import *

"""# Feature Function Declaration

## Function for Logic Part
"""

def get_plot_ranges(start=0, end=150, n=2.5):
    '''
    Make an iterator that divides into n or n+1 ranges. 
    - if end-start is divisible by steps, return n ranges
    - if end-start is not divisible by steps, return n+1 ranges, where the last range is smaller and ends at n
    
    # Example:
    >> list(get_plot_ranges())
    >> [(0.0, 3.0), (3.0, 6.0), (6.0, 9.0)]

    '''
    distance = end - start
    for i in np.arange(start, end, np.floor(distance/n)):
        yield (int(i), int(np.minimum(end, np.floor(distance/n) + i)))

def group_peaks(p, threshold=5):
    '''
    The peak detection algorithm finds multiple peaks for each QRS complex. 
    Here we group collections of peaks that are very near (within threshold) and we take the median index 
    '''
    # initialize output
    output = np.empty(0)

    # label groups of sample that belong to the same peak
    peak_groups, num_groups = label(np.diff(p) < threshold)

    # iterate through groups and take the mean as peak index
    for i in np.unique(peak_groups)[1:]:
        peak_group = p[np.where(peak_groups == i)]
        output = np.append(output, np.median(peak_group))
    return output

def detect_peaks(ecg_signal, threshold=0.3, qrs_filter=None):
    '''
    Peak detection algorithm using cross corrrelation and threshold 
    '''
    if qrs_filter is None:
        # create default qrs filter
        t = np.linspace(1.5 * np.pi, 3.5 * np.pi, 15)
        qrs_filter = np.sin(t)
    
    # normalize data
    ecg_signal = (ecg_signal - ecg_signal.mean()) / ecg_signal.std()

    # calculate cross correlation
    similarity = np.correlate(ecg_signal, qrs_filter, mode="same")
    similarity = similarity / np.max(similarity)

    # return peaks (values in ms) using threshold
    return ecg_signal[similarity > threshold].index, similarity


def get_rr_corrected(df):
  # detect peaks
  peaks, similarity = detect_peaks(df.ECG_Right, threshold=0.3)

  # group peaks so we get a single peak per beat (hopefully)
  grouped_peaks = group_peaks(peaks)

  # RR-intervals are the differences between successive peaks
  rr = np.diff(grouped_peaks)

  rr_corrected = rr.copy()
  rr_corrected[np.abs(zscore(rr)) > 2] = np.median(rr)
  return rr_corrected

def plot_rr_corrected(rr_corrected,rr):

   plt.title("RR-intervals", fontsize=24)
   plt.xlabel("Time (ms)", fontsize=16)
   plt.ylabel("RR-interval (ms)", fontsize=16)

   plt.plot(rr, color="red", linewidth=1, label="RR-intervals")
   plt.plot(rr_corrected, color="green", linewidth=2, label="RR-intervals after correction")
   plt.legend(fontsize=20)

def timedomain(rr):

   results = {}
  
   hr = 60000/rr
  
   # mean RR-interval
   results['Mean RR (ms)'] = np.mean(rr)
   results['STD RR/SDNN (ms)'] = np.std(rr)
   results['Mean HR (Kubios\' style) (beats/min)'] = 60000/np.mean(rr)
   results['Mean HR (beats/min)'] = np.mean(hr)
   results['STD HR (beats/min)'] = np.std(hr)
   results['Min HR (beats/min)'] = np.min(hr)
   results['Max HR (beats/min)'] = np.max(hr)
   results['RMSSD (ms)'] = np.sqrt(np.mean(np.square(np.diff(rr))))
   results['NNxx'] = np.sum(np.abs(np.diff(rr)) > 50)*1
   results['pNNxx (%)'] = 100 * np.sum((np.abs(np.diff(rr)) > 50)*1) / len(rr)
   print("Time domain metrics - automatically corrected RR-intervals:")
   for k, v in results.items():
        print("- %s: %.2f" % (k, v))
   return results

def frequency_domain(rr, fs=4):     #4

  # sample rate for interpolation
  steps = 1 / fs

  # create interpolation function based on the rr-samples. 
  x = np.cumsum(rr) / 1000.0
  f = interp1d(x, rr, kind='cubic',fill_value="extrapolate")

  # now we can sample from interpolation function
  xx = np.arange(1, np.max(x), steps)
  rr_interpolated = f(xx)
  # Estimate the spectral density using Welch's method
  fxx, pxx = signal.welch(x=rr_interpolated, fs=fs)
  
  '''
  Segement found frequencies in the bands 
    - Very Low Frequency (VLF): 0-0.04Hz 
    - Low Frequency (LF): 0.04-0.15Hz 
    - High Frequency (HF): 0.15-0.4Hz
  '''
  cond_vlf = (fxx >= 0) & (fxx < 0.04)
  cond_lf = (fxx >= 0.04) & (fxx < 0.15)
  cond_hf = (fxx >= 0.15) & (fxx < 0.4)
  
  # calculate power in each band by integrating the spectral density 
  vlf = trapz(pxx[cond_vlf], fxx[cond_vlf])
  lf = trapz(pxx[cond_lf], fxx[cond_lf])
  hf = trapz(pxx[cond_hf], fxx[cond_hf])
  
  # sum these up to get total power
  total_power = vlf + lf + hf

  # find which frequency has the most power in each band
  peak_vlf = fxx[cond_vlf][np.argmax(pxx[cond_vlf])]
  peak_lf = fxx[cond_lf][np.argmax(pxx[cond_lf])]
  peak_hf = fxx[cond_hf][np.argmax(pxx[cond_hf])]

  # fraction of lf and hf
  lf_nu = 100 * lf / (lf + hf)
  hf_nu = 100 * hf / (lf + hf)
  
  results = {}
  results['Power VLF (ms2)'] = vlf
  results['Power LF (ms2)'] = lf
  results['Power HF (ms2)'] = hf   
  results['Power Total (ms2)'] = total_power

  results['LF/HF'] = (lf/hf)
  results['Peak VLF (Hz)'] = peak_vlf
  results['Peak LF (Hz)'] = peak_lf
  results['Peak HF (Hz)'] = peak_hf

  results['Fraction LF (nu)'] = lf_nu
  results['Fraction HF (nu)'] = hf_nu
  
  print("Frequency domain metrics:")
  for k, v in results.items():
      print("- %s: %.2f" % (k, v))
  return results, fxx, pxx
def get_rr_corrected_ourdata(df):
  # detect peaks
  t = np.linspace(1.5 * np.pi, 3.5 * np.pi,13)
  qrs_filter = -np.sin(t)
  peaks, similarity = detect_peaks(df.ECG_Left, threshold=0.03,qrs_filter=qrs_filter)
 
  # group peaks so we get a single peak per beat (hopefully)
  grouped_peaks = group_peaks(peaks,threshold=3)
  # print(grouped_peaks)

  final=[element * 65 for element in grouped_peaks] 
  # print(final)
  # RR-intervals are the differences between successive peaks
  rr = np.diff(final)

  rr_corrected = rr.copy()
  rr_corrected[np.abs(zscore(rr)) > 2] = np.median(rr)
  return rr_corrected

def windowing(df,windowsizerow):
  # print("in function1")
  # column_names=['Mean RR (ms)', 'STD RR/SDNN (ms)', "Mean HR (Kubios' style) (beats/min)", 'Mean HR (beats/min)', 'STD HR (beats/min)', 'Min HR (beats/min)', 'Max HR (beats/min)', 'RMSSD (ms)', 'NNxx', 'pNNxx (%)', 'Power VLF (ms2)', 'Power LF (ms2)', 'Power HF (ms2)', 'Power Total (ms2)', 'LF/HF', 'Peak VLF (Hz)', 'Peak LF (Hz)', 'Peak HF (Hz)', 'Fraction LF (nu)', 'Fraction HF (nu)']
  column_names=['mean_nni','sdnn','sdsd','rmssd','median_nni','nni_50','pnni_50','nni_20','pnni_20','range_nni','cvsd','cvnni','mean_hr','max_hr','min_hr','std_hr','triangular_index','tinn','total_power','vlf','lf','hf','lf_hf_ratio','lfnu','hfnu','csi','cvi','Modified_csi','sd1','sd2','ratio_sd2_sd1','sampen']
  result_df= pd.DataFrame(columns=column_names) 
  df1=df.rolling(window=windowsizerow)
  # type(df1)
  i=1
  j=0
  for df2 in df1:
    if len(df2)>=windowsizerow and i%int(windowsizerow/1)==0:
      results_td=[]
      results_gd=[]
      results_fd=[]
      results_ccd=[]
      results_ppd=[]
      results_sampen=[]
      results=[]
      rr_corrected= get_rr_corrected_ourdata(df2)   
  

      interpolated_rr_intervals = interpolate_nan_values(rr_corrected,interpolation_method="linear")

      results_td=get_time_domain_features(interpolated_rr_intervals)
      results_gd=get_geometrical_features(interpolated_rr_intervals)
      results_fd=get_frequency_domain_features(interpolated_rr_intervals,"welch",128)
      results_ccd=get_csi_cvi_features(interpolated_rr_intervals)
      results_ppd=get_poincare_plot_features(interpolated_rr_intervals)
      results_sampen=get_sampen(interpolated_rr_intervals)


      results={**results_td,**results_gd,**results_fd,**results_ccd,**results_ppd,**results_sampen}
      # print("in function")
      # print(results)
      result_df=result_df.append(results,ignore_index=True)
    i+=1
    j+=1
  return result_df

"""## Function for Feature Extraction

User18
"""

df=pd.read_csv("/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/user18_vid1.csv")
p=df.drop(['AF3','F7','F3','FC5', 'T7', 'P7', 'O1', 'O2', 'P8','T8', 'FC6', 'F4', 'F8', 'AF4','GSR','ECG_Right' ], axis=1)
df2 = p.tail(6400)

def baseline_stress_features(input_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/user18_vid1.csv",output_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features",partnumber="User18"):
  column_names=['mean_nni','sdnn','sdsd','rmssd','median_nni','nni_50','pnni_50','nni_20','pnni_20','range_nni','cvsd','cvnni','mean_hr','max_hr','min_hr','std_hr','triangular_index','tinn','total_power','vlf','lf','hf','lf_hf_ratio','lfnu','hfnu','csi','cvi','Modified_csi','sd1','sd2','ratio_sd2_sd1','sampen']

result_df=windowing(df2,512)
result_df.shape
result_df.to_csv('/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features/R/vid1_ecg.csv')

df=pd.read_csv("/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/user18_vid2.csv")
p=df.drop(['AF3','F7','F3','FC5', 'T7', 'P7', 'O1', 'O2', 'P8','T8', 'FC6', 'F4', 'F8', 'AF4','GSR', 'ECG_Right' ], axis=1)
df2 = p.tail(6400)

def baseline_stress_features(input_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/user18_vid2.csv",output_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features",partnumber="User18"):
  column_names=['mean_nni','sdnn','sdsd','rmssd','median_nni','nni_50','pnni_50','nni_20','pnni_20','range_nni','cvsd','cvnni','mean_hr','max_hr','min_hr','std_hr','triangular_index','tinn','total_power','vlf','lf','hf','lf_hf_ratio','lfnu','hfnu','csi','cvi','Modified_csi','sd1','sd2','ratio_sd2_sd1','sampen']

result_df=windowing(df2,512)
result_df.shape
result_df.to_csv('/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features/R/vid2_ecg.csv')

df=pd.read_csv("/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/user18_vid3.csv")
p=df.drop(['AF3','F7','F3','FC5', 'T7', 'P7', 'O1', 'O2', 'P8','T8', 'FC6', 'F4', 'F8', 'AF4','GSR', 'ECG_Right' ], axis=1)
df2 = p.tail(6400)

def baseline_stress_features(input_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/user18_vid3.csv",output_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features",partnumber="User18"):
  column_names=['mean_nni','sdnn','sdsd','rmssd','median_nni','nni_50','pnni_50','nni_20','pnni_20','range_nni','cvsd','cvnni','mean_hr','max_hr','min_hr','std_hr','triangular_index','tinn','total_power','vlf','lf','hf','lf_hf_ratio','lfnu','hfnu','csi','cvi','Modified_csi','sd1','sd2','ratio_sd2_sd1','sampen']

result_df=windowing(df2,512)
result_df.shape
result_df.to_csv('/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features/R/vid3_ecg.csv')

df=pd.read_csv("/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/user18_vid4.csv")
p=df.drop(['AF3','F7','F3','FC5', 'T7', 'P7', 'O1', 'O2', 'P8','T8', 'FC6', 'F4', 'F8', 'AF4','GSR', 'ECG_Right' ], axis=1)
df2 = p.tail(6400)

def baseline_stress_features(input_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/user18_vid4.csv",output_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features",partnumber="User18"):
  column_names=['mean_nni','sdnn','sdsd','rmssd','median_nni','nni_50','pnni_50','nni_20','pnni_20','range_nni','cvsd','cvnni','mean_hr','max_hr','min_hr','std_hr','triangular_index','tinn','total_power','vlf','lf','hf','lf_hf_ratio','lfnu','hfnu','csi','cvi','Modified_csi','sd1','sd2','ratio_sd2_sd1','sampen']

result_df=windowing(df2,512)
result_df.shape
result_df.to_csv('/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features/R/vid4_ecg.csv')

df=pd.read_csv("/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/user18_vid5.csv")
p=df.drop(['AF3','F7','F3','FC5', 'T7', 'P7', 'O1', 'O2', 'P8','T8', 'FC6', 'F4', 'F8', 'AF4','GSR', 'ECG_Right' ], axis=1)
df2 = p.tail(6400)

def baseline_stress_features(input_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/user18_vid5.csv",output_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features",partnumber="User18"):
  column_names=['mean_nni','sdnn','sdsd','rmssd','median_nni','nni_50','pnni_50','nni_20','pnni_20','range_nni','cvsd','cvnni','mean_hr','max_hr','min_hr','std_hr','triangular_index','tinn','total_power','vlf','lf','hf','lf_hf_ratio','lfnu','hfnu','csi','cvi','Modified_csi','sd1','sd2','ratio_sd2_sd1','sampen']

result_df=windowing(df2,512)
result_df.shape
result_df.to_csv('/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features/R/vid5_ecg.csv')

df=pd.read_csv("/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/user18_vid6.csv")
p=df.drop(['AF3','F7','F3','FC5', 'T7', 'P7', 'O1', 'O2', 'P8','T8', 'FC6', 'F4', 'F8', 'AF4','GSR', 'ECG_Right' ], axis=1)
df2 = p.tail(6400)

def baseline_stress_features(input_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/user18_vid6.csv",output_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features",partnumber="User18"):
  column_names=['mean_nni','sdnn','sdsd','rmssd','median_nni','nni_50','pnni_50','nni_20','pnni_20','range_nni','cvsd','cvnni','mean_hr','max_hr','min_hr','std_hr','triangular_index','tinn','total_power','vlf','lf','hf','lf_hf_ratio','lfnu','hfnu','csi','cvi','Modified_csi','sd1','sd2','ratio_sd2_sd1','sampen']

result_df=windowing(df2,512)
result_df.shape
result_df.to_csv('/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features/R/vid6_ecg.csv')

df=pd.read_csv("/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/user18_vid7.csv")
p=df.drop(['AF3','F7','F3','FC5', 'T7', 'P7', 'O1', 'O2', 'P8','T8', 'FC6', 'F4', 'F8', 'AF4','GSR', 'ECG_Right' ], axis=1)
df2 = p.tail(6400)

def baseline_stress_features(input_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/user18_vid7.csv",output_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features",partnumber="User18"):
  column_names=['mean_nni','sdnn','sdsd','rmssd','median_nni','nni_50','pnni_50','nni_20','pnni_20','range_nni','cvsd','cvnni','mean_hr','max_hr','min_hr','std_hr','triangular_index','tinn','total_power','vlf','lf','hf','lf_hf_ratio','lfnu','hfnu','csi','cvi','Modified_csi','sd1','sd2','ratio_sd2_sd1','sampen']

result_df=windowing(df2,512)
result_df.shape
result_df.to_csv('/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features/R/vid7_ecg.csv')

df=pd.read_csv("/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User17/short_videos/user17_vid8.csv")
p=df.drop(['AF3','F7','F3','FC5', 'T7', 'P7', 'O1', 'O2', 'P8','T8', 'FC6', 'F4', 'F8', 'AF4','GSR', 'ECG_Right' ], axis=1)
df2 = p.tail(6400)

def baseline_stress_features(input_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User17/short_videos/user17_vid8.csv",output_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features",partnumber="User18"):
  column_names=['mean_nni','sdnn','sdsd','rmssd','median_nni','nni_50','pnni_50','nni_20','pnni_20','range_nni','cvsd','cvnni','mean_hr','max_hr','min_hr','std_hr','triangular_index','tinn','total_power','vlf','lf','hf','lf_hf_ratio','lfnu','hfnu','csi','cvi','Modified_csi','sd1','sd2','ratio_sd2_sd1','sampen']

result_df=windowing(df2,512)
result_df.shape
result_df.to_csv('/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features/R/vid8_ecg.csv')

df=pd.read_csv("/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/user18_vid9.csv")
p=df.drop(['AF3','F7','F3','FC5', 'T7', 'P7', 'O1', 'O2', 'P8','T8', 'FC6', 'F4', 'F8', 'AF4','GSR', 'ECG_Right' ], axis=1)
df2 = p.tail(6400)

def baseline_stress_features(input_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/user18_vid9.csv",output_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features",partnumber="User18"):
  column_names=['mean_nni','sdnn','sdsd','rmssd','median_nni','nni_50','pnni_50','nni_20','pnni_20','range_nni','cvsd','cvnni','mean_hr','max_hr','min_hr','std_hr','triangular_index','tinn','total_power','vlf','lf','hf','lf_hf_ratio','lfnu','hfnu','csi','cvi','Modified_csi','sd1','sd2','ratio_sd2_sd1','sampen']

result_df=windowing(df2,512)
result_df.shape
result_df.to_csv('/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features/R/vid9_ecg.csv')

df=pd.read_csv("/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/user18_vid10.csv")
p=df.drop(['AF3','F7','F3','FC5', 'T7', 'P7', 'O1', 'O2', 'P8','T8', 'FC6', 'F4', 'F8', 'AF4','GSR', 'ECG_Right' ], axis=1)
df2 = p.tail(6400)

def baseline_stress_features(input_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/user18_vid10.csv",output_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features",partnumber="User18"):
  column_names=['mean_nni','sdnn','sdsd','rmssd','median_nni','nni_50','pnni_50','nni_20','pnni_20','range_nni','cvsd','cvnni','mean_hr','max_hr','min_hr','std_hr','triangular_index','tinn','total_power','vlf','lf','hf','lf_hf_ratio','lfnu','hfnu','csi','cvi','Modified_csi','sd1','sd2','ratio_sd2_sd1','sampen']

result_df=windowing(df2,512)
result_df.shape
result_df.to_csv('/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features/R/vid10_ecg.csv')

df=pd.read_csv("/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/user18_vid11.csv")
p=df.drop(['AF3','F7','F3','FC5', 'T7', 'P7', 'O1', 'O2', 'P8','T8', 'FC6', 'F4', 'F8', 'AF4','GSR', 'ECG_Right' ], axis=1)
df2 = p.tail(6400)

def baseline_stress_features(input_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/user18_vid11.csv",output_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features",partnumber="User18"):
  column_names=['mean_nni','sdnn','sdsd','rmssd','median_nni','nni_50','pnni_50','nni_20','pnni_20','range_nni','cvsd','cvnni','mean_hr','max_hr','min_hr','std_hr','triangular_index','tinn','total_power','vlf','lf','hf','lf_hf_ratio','lfnu','hfnu','csi','cvi','Modified_csi','sd1','sd2','ratio_sd2_sd1','sampen']

result_df=windowing(df2,512)
result_df.shape
result_df.to_csv('/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features/R/vid11_ecg.csv')

df=pd.read_csv("/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/user18_vid12.csv")
p=df.drop(['AF3','F7','F3','FC5', 'T7', 'P7', 'O1', 'O2', 'P8','T8', 'FC6', 'F4', 'F8', 'AF4','GSR', 'ECG_Right' ], axis=1)
df2 = p.tail(6400)

def baseline_stress_features(input_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/user18_vid12.csv",output_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features",partnumber="User18"):
  column_names=['mean_nni','sdnn','sdsd','rmssd','median_nni','nni_50','pnni_50','nni_20','pnni_20','range_nni','cvsd','cvnni','mean_hr','max_hr','min_hr','std_hr','triangular_index','tinn','total_power','vlf','lf','hf','lf_hf_ratio','lfnu','hfnu','csi','cvi','Modified_csi','sd1','sd2','ratio_sd2_sd1','sampen']

result_df=windowing(df2,512)
result_df.shape
result_df.to_csv('/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features/R/vid12_ecg.csv')

df=pd.read_csv("/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User5/short_videos/user5_vid13.csv")
p=df.drop(['AF3','F7','F3','FC5', 'T7', 'P7', 'O1', 'O2', 'P8','T8', 'FC6', 'F4', 'F8', 'AF4','GSR', 'ECG_Right' ], axis=1)
df2 = p.tail(6400)

def baseline_stress_features(input_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User5/short_videos/user5_vid13.csv",output_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features",partnumber="User18"):
  column_names=['mean_nni','sdnn','sdsd','rmssd','median_nni','nni_50','pnni_50','nni_20','pnni_20','range_nni','cvsd','cvnni','mean_hr','max_hr','min_hr','std_hr','triangular_index','tinn','total_power','vlf','lf','hf','lf_hf_ratio','lfnu','hfnu','csi','cvi','Modified_csi','sd1','sd2','ratio_sd2_sd1','sampen']

result_df=windowing(df2,512)
result_df.shape
result_df.to_csv('/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features/R/vid13_ecg.csv')

df=pd.read_csv("/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/user18_vid14.csv")
p=df.drop(['AF3','F7','F3','FC5', 'T7', 'P7', 'O1', 'O2', 'P8','T8', 'FC6', 'F4', 'F8', 'AF4','GSR', 'ECG_Right' ], axis=1)
df2 = p.tail(6400)

def baseline_stress_features(input_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/user18_vid14.csv",output_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features",partnumber="User18"):
  column_names=['mean_nni','sdnn','sdsd','rmssd','median_nni','nni_50','pnni_50','nni_20','pnni_20','range_nni','cvsd','cvnni','mean_hr','max_hr','min_hr','std_hr','triangular_index','tinn','total_power','vlf','lf','hf','lf_hf_ratio','lfnu','hfnu','csi','cvi','Modified_csi','sd1','sd2','ratio_sd2_sd1','sampen']

result_df=windowing(df2,512)
result_df.shape
result_df.to_csv('/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features/R/vid14_ecg.csv')

df=pd.read_csv("/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/user18_vid15.csv")
p=df.drop(['AF3','F7','F3','FC5', 'T7', 'P7', 'O1', 'O2', 'P8','T8', 'FC6', 'F4', 'F8', 'AF4','GSR', 'ECG_Right' ], axis=1)
df2 = p.tail(6400)

def baseline_stress_features(input_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/user18_vid15.csv",output_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features",partnumber="User18"):
  column_names=['mean_nni','sdnn','sdsd','rmssd','median_nni','nni_50','pnni_50','nni_20','pnni_20','range_nni','cvsd','cvnni','mean_hr','max_hr','min_hr','std_hr','triangular_index','tinn','total_power','vlf','lf','hf','lf_hf_ratio','lfnu','hfnu','csi','cvi','Modified_csi','sd1','sd2','ratio_sd2_sd1','sampen']

result_df=windowing(df2,512)
result_df.shape
result_df.to_csv('/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features/R/vid15_ecg.csv')

df=pd.read_csv("/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/user18_vid16.csv")
p=df.drop(['AF3','F7','F3','FC5', 'T7', 'P7', 'O1', 'O2', 'P8','T8', 'FC6', 'F4', 'F8', 'AF4','GSR', 'ECG_Right' ], axis=1)
df2 = p.tail(6400)

def baseline_stress_features(input_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/user18_vid16.csv",output_path=r"/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features",partnumber="User18"):
  column_names=['mean_nni','sdnn','sdsd','rmssd','median_nni','nni_50','pnni_50','nni_20','pnni_20','range_nni','cvsd','cvnni','mean_hr','max_hr','min_hr','std_hr','triangular_index','tinn','total_power','vlf','lf','hf','lf_hf_ratio','lfnu','hfnu','csi','cvi','Modified_csi','sd1','sd2','ratio_sd2_sd1','sampen']

result_df=windowing(df2,512)
result_df.shape
result_df.to_csv('/content/drive/MyDrive/Datasets/Amigos/Mat_toCSV/User18/short_videos/Ecg_features/R/vid16_ecg.csv')