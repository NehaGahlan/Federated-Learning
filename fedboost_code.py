# -*- coding: utf-8 -*-
"""FedBoost_code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_yuY6mQ9j3CaiXSohA4pZGzAGUZl-9fU
"""

import tensorflow as tf
import tensorflow_federated as tff
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import numpy as np

# Define a function to create a ann model
def create_model():
    model = tf.keras.Sequential([
        tf.keras.layers.Dense(128, activation='relu', input_shape=(168,)),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(64, activation='softmax'),
        tf.keras.layers.Dropout(o.2)
    ])
    return model

# Wrap the model in a TFF keras model
def create_tff_model():
    keras_model = create_model()
    return tff.learning.from_keras_model(keras_model, input_spec=X_train.shape)

# Create a federated dataset
def create_federated_data():
    client_ids = np.arange(len(X_train))
    train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(X_train)).batch(10)
    federated_train_data = [train_data.filter(lambda x, y: i == x).repeat().batch(10)
                            for i in client_ids]
    return federated_train_data

# Define the FedBoost algorithm
def federated_boost(federated_train_data, num_boosting_rounds, client_weight_fn):
    models = []
    num_clients = len(federated_train_data)
    weights = np.ones(num_clients) / num_clients

    for boosting_round in range(num_boosting_rounds):
        # Train the local models
        local_models = []
        for i in range(num_clients):
            model = create_tff_model()
            tff.learning.assign_weights_to_keras_model(model, models[-1])
            optimizer = tf.keras.optimizers.Adam(learning_rate=0.02)
            tff.learning.build_federated_averaging_process(model.compile(optimizer=optimizer)).initialize()
            federated_train_data_i = federated_train_data[i]
            client_weight_i = client_weight_fn(i, weights)
            local_model = tff.learning.build_federated_averaging_process(model.compile(optimizer=optimizer)).run(federated_train_data_i, 
                client_weight=client_weight_i)
            local_models.append(local_model)

        # Calculate the loss and update the client weights
        losses = []
        for i in range(num_clients):
            loss = local_models[i].evaluate()
            losses.append(loss)
        min_loss = min(losses)
        weights *= np.exp(-0.5 * (losses - min_loss))
        weights /= np.sum(weights)

        # Combine the local models and store the boosted model
        boosted_model = tff.learning.build_federated_averaging_process(model.compile(optimizer=optimizer)).initialize()
        for i in range(num_clients):
            tff.learning.state_with_new_model_weights(boosted_model, local_models[i].weights)
        models.append(boosted_model)

    return models

# Train the model using FedBoost
federated_train_data = create_federated_data()
models = federated_boost(federated_train_data, 50, lambda i, weights: weights[i])

# Evaluate the final model on the test data
test_loss, test_acc = models[-1].evaluate(X_test, y_test, verbose=0)
print('Test accuracy:', test_acc)